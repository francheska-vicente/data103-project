{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a588d9c",
   "metadata": {},
   "source": [
    "# You Matter, Words Matter: A Suicide Prevention Tool\n",
    "In this notebook, you can try out the different models trained in order to detect if the text inputted is suicidal or not.\n",
    "\n",
    "**DATA103 S11 Group 4**\n",
    "- GOZON, Jean Pauline D.\n",
    "- JAMIAS, Gillian Nicole A.\n",
    "- MARCELO Andrea Jean C. \n",
    "- REYES, Anton Gabriel G.\n",
    "- VICENTE, Francheska Josefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef4019",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71631da",
   "metadata": {},
   "source": [
    "**Basic Libraries**\n",
    "\n",
    "Import `numpy`, `pandas`, and `datasets`.\n",
    "\n",
    "* `numpy` contains a large collection of mathematical functions\n",
    "* `pandas` contains functions that are designed for data manipulation and data analysis\n",
    "* `datasets` contains functions that allow easier pre-processing for datasets and smart caching for easier loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff629da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb90f65",
   "metadata": {},
   "source": [
    "**Natural Language Processing Libraries** \n",
    "\n",
    "The next imports are libraries that can implement feature engineering techniques on the text input. \n",
    "* `re` is a module that allows the use of regular expressions\n",
    "* `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features\n",
    "* `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6c842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022cfe38",
   "metadata": {},
   "source": [
    "**Machine Learning Libraries**\n",
    "\n",
    "`pickle` is a module that can serialize and deserialize objects. In this notebook, it is used to save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153485a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9ff89",
   "metadata": {},
   "source": [
    "The following classes are classifiers that implement different methods of classification.\n",
    "* `LogisticRegression` is a class under the linear models module that implements regularized logistic regression\n",
    "* `MultinomialNB` is a class under the Naive Bayes module that allows the classification of discrete features\n",
    "* `RandomForestClassifier` is a class under the ensemble module that trains by fitting using a number of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abad2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76045a00",
   "metadata": {},
   "source": [
    "Last, `requests` is a library that allows us to send requests to the Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756b1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7f2e5",
   "metadata": {},
   "source": [
    "## Model Imports\n",
    "To use the model, let us import each of the model that we used, starting with the vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8765cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./saved_models/trad_ml/vectorizers/count.pkl', \"rb\") as file:\n",
    "    count_vectorizer = pickle.load(file)\n",
    "    \n",
    "with open ('./saved_models/trad_ml/vectorizers/tfidf.pkl', \"rb\") as file:\n",
    "    tfidf_vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cfc9dc",
   "metadata": {},
   "source": [
    "Before we move on to importing the models, let us first declare the list that would hold the models that we will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1de22",
   "metadata": {},
   "source": [
    "Now, we can continue with importing the models (that utilized traditional machine learning algorithms) that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8abab2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_models = []\n",
    "tfidf_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43f9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['logreg', 'logreg_tuned', 'mnb', 'mnb_tuned']\n",
    "\n",
    "for temp in file_names:\n",
    "    with open ('./saved_models/trad_ml/' + temp + '/count/model.pkl', \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "        count_models.append(model)\n",
    "        \n",
    "    with open ('./saved_models/trad_ml/' + temp + '/tfidf/model.pkl', \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "        tfidf_models.append(model)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a1c03",
   "metadata": {},
   "source": [
    "Next, let us declare the URL and the header that will allow us to send requests to the BERT and the RoBERTa models from the Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40451646",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_API_URL = \"https://api-inference.huggingface.co/models/francheska-vicente/data103-roberta-base-v1\"\n",
    "roberta_headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "BERT_API_URL = \"https://api-inference.huggingface.co/models/francheska-vicente/data103-bert-base-v2\"\n",
    "bert_headers = {\"Authorization\": \"Bearer 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\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a2a9f5",
   "metadata": {},
   "source": [
    "Last, we will be defining the function that will send the request to the Hub and accept the response of the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b54496f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(payload, url, header):\n",
    "    response = requests.post(url, headers=header, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6985d6",
   "metadata": {},
   "source": [
    "## Declaration of Functions \n",
    "\n",
    "Before we start with the prediction proper, we will have to define the functions that will be used.\n",
    "\n",
    "First, the `remove_unnecessary` function will remove the words that we deem as unnecessary (i.e., retweets, usernames, media links, square brackets, and hashtags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48104adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary(text):\n",
    "    text = re.sub('RT', '', text) # RT\n",
    "    text = re.sub('@[^\\s]+', '', text) # usernames\n",
    "    text = re.sub('http[^\\s]+','',text) # media links\n",
    "    text = re.sub(r'\\[|\\]', '', text) # square brackets\n",
    "    text = re.sub('#[^ ]+', '', text) # hashtags\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f578a0",
   "metadata": {},
   "source": [
    "Next, the `clean_input` function is the function that will call all functions that will be used for pre-processing and cleaning. This will be used for the models that utilized traditional machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a81b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input (text):\n",
    "    text = remove_unnecessary (text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a7844",
   "metadata": {},
   "source": [
    "This is followed by the functions that will be used for formatting the output of the predictions. The `determine_output` is the function that will convert the response of the Huggingface Hub into the same format as the output of traditional machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cefc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_output (output):\n",
    "\n",
    "    positive = output[0][1]['score']\n",
    "    negative = output[0][0]['score']\n",
    "    label = 0\n",
    "    \n",
    "    if output[0][0]['label'] == 'Suicidal':\n",
    "        positive = output[0][0]['score']\n",
    "        negative = output[0][1]['score']\n",
    "    \n",
    "    probability = negative \n",
    "    \n",
    "    if positive >= 0.5:\n",
    "        label = 1\n",
    "        probability = positive\n",
    " \n",
    "    return [label, probability * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31ec6b",
   "metadata": {},
   "source": [
    "Last, the `output_probabilities` function will format the output of the models to make it more understandable and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4686ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_probabilities (predictions, probabilities):\n",
    "    labels = ['Logistic Regression (Count)', 'Tuned Logistic Regression  (Count)',\n",
    "              'Multinomial Naive Bayes  (Count)', 'Tuned Multinomial Naive Bayes  (Count)',\n",
    "              'Logistic Regression (TF-IDF)', 'Tuned Logistic Regression (TF-IDF)',\n",
    "              'Multinomial Naive Bayes (TF-IDF)', 'Tuned Multinomial Naive Bayes (TF-IDF)']\n",
    "\n",
    "    temp_index = 0\n",
    "    \n",
    "    for i in range (len(labels)):\n",
    "        predict_label = 'non-suicidal'\n",
    "        \n",
    "        curr_probability = probabilities [i][0]\n",
    "        probability_label = round(curr_probability [0] * 100, 2) \n",
    "        if (predictions [i] == 1):\n",
    "            predict_label = 'suicidal'\n",
    "            probability_label = round(curr_probability [1] * 100, 2)  \n",
    "        \n",
    "        print ('According to the ' + labels [i] + ' model, there is a ' + str(probability_label) + \n",
    "               '% chance that your text is ' + predict_label + '.')\n",
    "        \n",
    "        temp_index = i\n",
    "    \n",
    "    temp_index = temp_index + 1\n",
    "    next_labels = ['BERT', 'RoBERTa']\n",
    "    for temp in (next_labels):\n",
    "        if temp_index != len(probabilities): \n",
    "            probability_label = round(probabilities [temp_index], 2)   \n",
    "            predict_label = predictions [temp_index]\n",
    "            \n",
    "            if predict_label == 1:\n",
    "                predict_label = 'suicidal'\n",
    "            else:\n",
    "                predict_label = 'non-suicidal'\n",
    "            \n",
    "            print ('According to the ' + temp + ' model, there is a ' + str(probability_label) + \n",
    "                   '% chance that your text is ' + predict_label + '.')\n",
    "            temp_index = temp_index + 1\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261158e",
   "metadata": {},
   "source": [
    "## Try out our model!\n",
    "Now, you can use our models! Enter **STOP** if you want to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f213795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: I don't want to commit suicide.\n",
      "According to the Logistic Regression (Count) model, there is a 62.34% chance that your text is suicidal.\n",
      "According to the Tuned Logistic Regression  (Count) model, there is a 70.93% chance that your text is suicidal.\n",
      "According to the Multinomial Naive Bayes  (Count) model, there is a 99.38% chance that your text is suicidal.\n",
      "According to the Tuned Multinomial Naive Bayes  (Count) model, there is a 99.32% chance that your text is suicidal.\n",
      "According to the Logistic Regression (TF-IDF) model, there is a 99.92% chance that your text is suicidal.\n",
      "According to the Tuned Logistic Regression (TF-IDF) model, there is a 99.92% chance that your text is suicidal.\n",
      "According to the Multinomial Naive Bayes (TF-IDF) model, there is a 95.45% chance that your text is suicidal.\n",
      "According to the Tuned Multinomial Naive Bayes (TF-IDF) model, there is a 94.58% chance that your text is suicidal.\n",
      "According to the BERT model, there is a 97.51% chance that your text is suicidal.\n",
      "According to the RoBERTa model, there is a 92.09% chance that your text is suicidal.\n",
      "\n",
      "Enter text: I want to commit suicide.\n",
      "According to the Logistic Regression (Count) model, there is a 61.52% chance that your text is suicidal.\n",
      "According to the Tuned Logistic Regression  (Count) model, there is a 70.4% chance that your text is suicidal.\n",
      "According to the Multinomial Naive Bayes  (Count) model, there is a 98.99% chance that your text is suicidal.\n",
      "According to the Tuned Multinomial Naive Bayes  (Count) model, there is a 98.92% chance that your text is suicidal.\n",
      "According to the Logistic Regression (TF-IDF) model, there is a 99.94% chance that your text is suicidal.\n",
      "According to the Tuned Logistic Regression (TF-IDF) model, there is a 99.95% chance that your text is suicidal.\n",
      "According to the Multinomial Naive Bayes (TF-IDF) model, there is a 95.06% chance that your text is suicidal.\n",
      "According to the Tuned Multinomial Naive Bayes (TF-IDF) model, there is a 94.25% chance that your text is suicidal.\n",
      "According to the BERT model, there is a 98.94% chance that your text is suicidal.\n",
      "According to the RoBERTa model, there is a 92.09% chance that your text is suicidal.\n",
      "\n",
      "Enter text: STOP\n"
     ]
    }
   ],
   "source": [
    "text = input ('Enter text: ').strip ()\n",
    "\n",
    "while (text.lower() != 'stop'):\n",
    "    count_text = count_vectorizer.transform ([clean_input (text)])\n",
    "    tfidf_text = tfidf_vectorizer.transform ([clean_input (text)])\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    for curr_model in count_models:\n",
    "        predictions.append(curr_model.predict(count_text))\n",
    "        probabilities.append(curr_model.predict_proba(count_text))\n",
    "        \n",
    "    for curr_model in tfidf_models:\n",
    "        predictions.append(curr_model.predict(tfidf_text))\n",
    "        probabilities.append(curr_model.predict_proba(tfidf_text))\n",
    "    \n",
    "    try:\n",
    "        bert_output = determine_output(query(text, BERT_API_URL, bert_headers))\n",
    "        roberta_output = determine_output(query(text, ROBERTA_API_URL, roberta_headers))\n",
    "        \n",
    "        predictions.append(bert_output [0])\n",
    "        probabilities.append(bert_output [1])\n",
    "        \n",
    "        predictions.append(roberta_output [0])\n",
    "        probabilities.append(roberta_output [1])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"The BERT and/or RoBERTa models are still being loaded to the Huggingface Hub.\")\n",
    "    \n",
    "    output_probabilities (predictions, probabilities)\n",
    "    \n",
    "    text = input ('Enter text: ').strip ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
