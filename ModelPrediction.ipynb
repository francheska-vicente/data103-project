{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be15845",
   "metadata": {},
   "source": [
    "# **Insert Title Here**\n",
    "In this notebook, you can try out the different models trained in order to detect if the text inputted is suicidal or not.\n",
    "\n",
    "**DATA103 S11 Group 4**\n",
    "- GOZON, Jean Pauline D.\n",
    "- JAMIAS, Gillian Nicole A.\n",
    "- MARCELO Andrea Jean C. \n",
    "- REYES, Anton Gabriel G.\n",
    "- VICENTE, Francheska Josefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccdfd42",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf350d",
   "metadata": {},
   "source": [
    "**Basic Libraries**\n",
    "\n",
    "Import `numpy`, `pandas`, and `datasets`.\n",
    "\n",
    "* `numpy` contains a large collection of mathematical functions\n",
    "* `pandas` contains functions that are designed for data manipulation and data analysis\n",
    "* `datasets` contains functions that allow easier pre-processing for datasets and smart caching for easier loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d2c8d",
   "metadata": {},
   "source": [
    "**Natural Language Processing Libraries** \n",
    "\n",
    "The next imports are libraries that can implement feature engineering techniques on the text input. \n",
    "* `re` is a module that allows the use of regular expressions\n",
    "* `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features\n",
    "* `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d706985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb051a0",
   "metadata": {},
   "source": [
    "**Machine Learning Libraries**\n",
    "\n",
    "`pickle` is a module that can serialize and deserialize objects. In this notebook, it is used to save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a7464e",
   "metadata": {},
   "source": [
    "The following classes are classifiers that implement different methods of classification.\n",
    "* `LogisticRegression` is a class under the linear models module that implements regularized logistic regression\n",
    "* `MultinomialNB` is a class under the Naive Bayes module that allows the classification of discrete features\n",
    "* `RandomForestClassifier` is a class under the ensemble module that trains by fitting using a number of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ac063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a88f2",
   "metadata": {},
   "source": [
    "Last, `requests` is a library that allows us to send requests to the Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1178e4",
   "metadata": {},
   "source": [
    "## Model Imports\n",
    "To use the model, let us import each of the model that we used, starting with the vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a325a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./saved_models/trad_ml/vectorizers/count.pkl', \"rb\") as file:\n",
    "    count_vectorizer = pickle.load(file)\n",
    "    \n",
    "with open ('./saved_models/trad_ml/vectorizers/tfidf.pkl', \"rb\") as file:\n",
    "    tfidf_vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f058d9",
   "metadata": {},
   "source": [
    "Before we move on to importing the models, let us first declare the list that would hold the models that we will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba44ed",
   "metadata": {},
   "source": [
    "Now, we can continue with importing the models (that utilized traditional machine learning algorithms) that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ac6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_models = []\n",
    "tfidf_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['logreg', 'logreg_tuned', 'mnb', 'mnb_tuned']\n",
    "\n",
    "for temp in file_names:\n",
    "    with open ('./saved_models/trad_ml/' + temp + '/count/model.pkl', \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "        count_models.append(model)\n",
    "        \n",
    "    with open ('./saved_models/trad_ml/' + temp + '/tfidf/model.pkl', \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "        tfidf_models.append(model)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062fa375",
   "metadata": {},
   "source": [
    "Next, let us declare the URL and the header that will allow us to send requests to the BERT and the RoBERTa models from the Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa3fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_API_URL = \"https://api-inference.huggingface.co/models/francheska-vicente/data103-roberta-base-v1\"\n",
    "roberta_headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "BERT_API_URL = \"https://api-inference.huggingface.co/models/francheska-vicente/data103-bert-base-v2\"\n",
    "bert_headers = {\"Authorization\": \"Bearer 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\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da78fa",
   "metadata": {},
   "source": [
    "Last, we will be defining the function that will send the request to the Hub and accept the response of the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(payload, url, header):\n",
    "    response = requests.post(url, headers=header, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0db2e4",
   "metadata": {},
   "source": [
    "## Data Cleaning and Pre-processing\n",
    "\n",
    "Before we start with the prediction proper, we will have to define the functions that will be used for pre-processing and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c32eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary(text):\n",
    "    text = re.sub('RT', '', text) # RT\n",
    "    text = re.sub('@[^\\s]+', '', text) # usernames\n",
    "    text = re.sub('http[^\\s]+','',text) # media links\n",
    "    text = re.sub(r'\\[|\\]', '', text) # square brackets\n",
    "    text = re.sub('#[^ ]+', '', text) # hashtags\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input (text):\n",
    "    text = remove_unnecessary (text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d87cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_output (output):\n",
    "    negative = output[0][0]['score']\n",
    "    positive = output[0][1]['score']\n",
    "    \n",
    "    label = 0\n",
    "    probability = negative \n",
    "    \n",
    "    if positive >= 0.5:\n",
    "        label = 1\n",
    "        probability = positive\n",
    "        \n",
    "    return [label, probability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_probabilities (predictions, probabilities):\n",
    "    labels = ['Logistic Regression', 'Tuned Logistic Regression',\n",
    "             'Multinomial Naive Bayes', 'Tuned Multinomial Naive Bayes',\n",
    "             'BERT', 'RoBERTa']\n",
    "\n",
    "    for i in range (len(labels)):\n",
    "        predict_label = 'non-suicidal'\n",
    "        \n",
    "        curr_probability = probabilities [i][0]\n",
    "        probability_label = round(curr_probability [0] * 100, 2) \n",
    "        if (predictions [i] == 1):\n",
    "            predict_label = 'suicidal'\n",
    "            probability_label = round(curr_probability [1] * 100, 2)  \n",
    "        \n",
    "        print ('According to the ' + labels [i] + ' model, there is a ' + str(probability_label) + \n",
    "               '% chance that your text is ' + predict_label + '.')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8228b723",
   "metadata": {},
   "source": [
    "## Try out our model!\n",
    "Now, you can use our models! Enter **STOP** if you want to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bee963",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input ('Enter text: ').strip ()\n",
    "\n",
    "while (text.lower() != 'stop'):\n",
    "    count_text = count_vectorizer.transform ([clean_input (text)])\n",
    "    tfidf_text = tfidf_vectorizer.transform ([clean_input (text)])\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    for curr_model in count_models:\n",
    "        predictions.append(curr_model.predict(count_text))\n",
    "        probabilities.append(curr_model.predict_proba(count_text))\n",
    "        \n",
    "    for curr_model in tfidf_models:\n",
    "        predictions.append(curr_model.predict(tfidf_text))\n",
    "        probabilities.append(curr_model.predict_proba(tfidf_text))\n",
    "    \n",
    "    try:\n",
    "        bert_output = determine_output(query(text, BERT_API_URL, bert_headers))\n",
    "        roberta_output = determine_output(query(text, ROBERTA_API_URL, roberta_headers))\n",
    "    \n",
    "        predictions.append(bert_output [0])\n",
    "        probabilities.append(bert_output [1])\n",
    "    \n",
    "        predictions.append(roberta_output [0])\n",
    "        probabilities.append(roberta_output [1])\n",
    "    except:\n",
    "        print(\"The BERT and/or RoBERTa models are still being loaded in the Huggingface Hub.\")\n",
    "    \n",
    "    output_probabilities (predictions, probabilities)\n",
    "    \n",
    "    text = input ('Enter text: ').strip ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
