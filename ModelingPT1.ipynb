{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af09dee",
   "metadata": {},
   "source": [
    "# **Insert Title Here**\n",
    "**DATA103 S11 Group 4**\n",
    "- GOZON, Jean Pauline D.\n",
    "- JAMIAS, Gillian Nicole A.\n",
    "- MARCELO Andrea Jean C. \n",
    "- REYES, Anton Gabriel G.\n",
    "- VICENTE, Francheska Josefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d7015",
   "metadata": {},
   "source": [
    "## Requirements and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f8c6c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11375e10",
   "metadata": {},
   "source": [
    "**Basic Libraries**\n",
    "\n",
    "* `numpy` contains a large collection of mathematical functions\n",
    "* `pandas` contains functions that are designed for data manipulation and data analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e40c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5a973",
   "metadata": {},
   "source": [
    "**Machine Learning Libraries**\n",
    "\n",
    "* `torch` this is an open source ML library for deep neural network creation\n",
    "* `transformers` contains pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6747f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adbc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from pytorch_lightning.callbacks import ProgressBarBase, RichProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402c99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizerFast, AutoModelForSequenceClassification, TrainerCallback, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628195e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, hamming_loss, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505ff4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0a6b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['its not a viable option, and youll be leavin...</td>\n",
       "      <td>['its', 'not', 'a', 'viable', 'option', 'and',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['it can be hard to appreciate the notion that...</td>\n",
       "      <td>['it', 'can', 'be', 'hard', 'to', 'appreciate'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['hi, so last night i was sitting on the ledge...</td>\n",
       "      <td>['hi', 'so', 'last', 'night', 'i', 'was', 'sit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['i tried to kill my self once and failed badl...</td>\n",
       "      <td>['i', 'tried', 'to', 'kill', 'my', 'self', 'on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['hi nem3030. what sorts of things do you enjo...</td>\n",
       "      <td>['hi', 'nem3030', 'what', 'sorts', 'of', 'thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242155</th>\n",
       "      <td>0</td>\n",
       "      <td>if you don't like rock then your not going to ...</td>\n",
       "      <td>['if', 'you', 'don', 't', 'like', 'rock', 'the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242156</th>\n",
       "      <td>0</td>\n",
       "      <td>you how you can tell i have so many friends an...</td>\n",
       "      <td>['you', 'how', 'you', 'can', 'tell', 'i', 'hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242157</th>\n",
       "      <td>0</td>\n",
       "      <td>pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...</td>\n",
       "      <td>['pee', 'probably', 'tastes', 'like', 'salty',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242158</th>\n",
       "      <td>1</td>\n",
       "      <td>the usual stuff you find herei'm not posting t...</td>\n",
       "      <td>['the', 'usual', 'stuff', 'you', 'find', 'here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242159</th>\n",
       "      <td>0</td>\n",
       "      <td>i still haven't beaten the first boss in hollo...</td>\n",
       "      <td>['i', 'still', 'haven', 't', 'beaten', 'the', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242160 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                                               text  \\\n",
       "0           0  ['its not a viable option, and youll be leavin...   \n",
       "1           1  ['it can be hard to appreciate the notion that...   \n",
       "2           1  ['hi, so last night i was sitting on the ledge...   \n",
       "3           1  ['i tried to kill my self once and failed badl...   \n",
       "4           1  ['hi nem3030. what sorts of things do you enjo...   \n",
       "...       ...                                                ...   \n",
       "242155      0  if you don't like rock then your not going to ...   \n",
       "242156      0  you how you can tell i have so many friends an...   \n",
       "242157      0  pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...   \n",
       "242158      1  the usual stuff you find herei'm not posting t...   \n",
       "242159      0  i still haven't beaten the first boss in hollo...   \n",
       "\n",
       "                                               text_token  \n",
       "0       ['its', 'not', 'a', 'viable', 'option', 'and',...  \n",
       "1       ['it', 'can', 'be', 'hard', 'to', 'appreciate'...  \n",
       "2       ['hi', 'so', 'last', 'night', 'i', 'was', 'sit...  \n",
       "3       ['i', 'tried', 'to', 'kill', 'my', 'self', 'on...  \n",
       "4       ['hi', 'nem3030', 'what', 'sorts', 'of', 'thin...  \n",
       "...                                                   ...  \n",
       "242155  ['if', 'you', 'don', 't', 'like', 'rock', 'the...  \n",
       "242156  ['you', 'how', 'you', 'can', 'tell', 'i', 'hav...  \n",
       "242157  ['pee', 'probably', 'tastes', 'like', 'salty',...  \n",
       "242158  ['the', 'usual', 'stuff', 'you', 'find', 'here...  \n",
       "242159  ['i', 'still', 'haven', 't', 'beaten', 'the', ...  \n",
       "\n",
       "[242160 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('cleaned_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c8395",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55267fd6",
   "metadata": {},
   "source": [
    "### Splitting the Dataset into Train, Val, and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df ['text']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df ['class']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42, \n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train, \n",
    "                                                  test_size = 0.1,\n",
    "                                                  stratify = y_train,\n",
    "                                                  random_state = 42, \n",
    "                                                  shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23225dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train input  shape: ', X_train.shape)\n",
    "print('Train output shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Val input  shape: ', X_val.shape)\n",
    "print('Val output shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bf789",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test input  shape: ', X_test.shape)\n",
    "print('Test output shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis = 1).reset_index(drop = True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.concat([X_val, y_val], axis = 1).reset_index(drop = True)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test, y_test], axis = 1).reset_index(drop = True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff1409",
   "metadata": {},
   "source": [
    "### Tokenizing with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0922bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_pandas(train_df)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.Dataset.from_pandas(val_df)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.Dataset.from_pandas(test_df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict({\n",
    "    \"train\" : train_dataset, \n",
    "    \"val\" : val_dataset, \n",
    "    \"test\" : test_dataset\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    encoding = tokenizer(examples[\"text\"], padding = \"max_length\", truncation = True, max_length = MAX_LENGTH)\n",
    "    encoding[\"labels\"] = torch.tensor(examples ['class'])\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60484474",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ffcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf46040",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b11a4a",
   "metadata": {},
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1fa8f",
   "metadata": {},
   "source": [
    "#### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    return_dict = False\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir = \"bert_trainer\", \n",
    "                                  save_steps = 20000,\n",
    "                                  save_strategy = 'steps',\n",
    "                                  fp16 = True,\n",
    "                                  evaluation_strategy = \"epoch\", \n",
    "                                  resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    hamming_loss_score = hamming_loss(y_true = y_true, y_pred = y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # return as dictionary\n",
    "    metrics = {\n",
    "        'f1_micro_average': f1_micro_average,\n",
    "        'roc_auc': roc_auc, \n",
    "        'hamming_loss_score' : hamming_loss_score,\n",
    "        'f1_macro_average' : f1_macro_average,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f793f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = bert_model,\n",
    "    args = training_args,\n",
    "    train_dataset = encoded_dataset ['train'],\n",
    "    eval_dataset = encoded_dataset ['val'],\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks = [TrainerCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04397068",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024503e",
   "metadata": {},
   "source": [
    "#### Saving BERT base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ff1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_models ='./saved_models/BERTv1'\n",
    "trainer.save_model(path_for_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98fb25",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64581231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9c08d6b",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d8e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819108be",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0259ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
